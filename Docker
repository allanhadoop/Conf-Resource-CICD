# Source - https://prakhar.me/docker-curriculum/
# source - https://prakhar.me/docker-curriculum/
# Install Source - https://docs.docker.com/engine/installation/linux/ubuntulinux/
# an open-source project that automates the deployment of software applications inside containers by providing an additional layer of
# abstraction and automation of OS-level virtualization on Linux.
# VMs run applications inside a guest Operating System, which runs on virtual hardware powered by the server’s host OS.

sudo apt-get update
sudo apt-get install apt-transport-https ca-certificates
# Add the new GPG key. This commands downloads the key with the ID 58118E89F3A912897C070ADBF76221572C52609D from the keyserver 
# hkp://ha.pool.sks-keyservers.net:80 and adds it to the adv keychain. If the above keyserver is not available, 
# try hkp://pgp.mit.edu:80 or hkp://keyserver.ubuntu.com:80.

sudo apt-key adv \
               --keyserver hkp://ha.pool.sks-keyservers.net:80 \
               --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
# Add docker repository key to apt-key for package verification:

echo "deb https://apt.dockerproject.org/repo ubuntu-trusty main" | sudo tee /etc/apt/sources.list.d/docker.list
sudo apt-get update 
apt-cache policy docker-engine
# for ubuntu --- trusty below steps 
sudo apt-get install docker-engine
sudo service docker start
sudo groupadd docker
sudo usermod -aG docker $USER
sudo docker run hello-world

>> Cannot connect to the Docker daemon. Is 'docker daemon' running on this host?
env | grep DOCKER_HOST  --if nany entry find then unset it using unset DOCKER_HOST

sudo docker -d &     #start daemon

other linux distribution -- details at https://docs.docker.com/engine/getstarted/step_one/
-----------------------------------------------------------------------------------------
# Docker versions - Use different tags to create versions as shown below . 
# “Latest” simply means “the last build/tag that ran without a specific tag/version specified” so use different tags as shown below to pull latest image from docker hub if you push any updated version there.
          sudo docker build -t allan/test .
          sudo docker tag allan/test allan/test:2 
          ...
          sudo docker build -t allan/test .
          sudo docker tag allan/test:3
          ...

some terminology-
Images - The blueprints of our application which form the basis of containers. In the demo above, we used the docker pull command to download the busybox image.
Containers - Created from Docker images and run the actual application. We create a container using docker run which we did using the busybox image that we downloaded. A list of running containers can be seen using the docker ps command.
Docker Daemon - The background service running on the host that manages building, running and distributing Docker containers. The daemon is the process that runs in the operation system to which clients talk to.
Docker Client - The command line tool that allows the user to interact with the daemon. More generally, there can be other forms of clients too - such as Kitematic which provide a GUI to the users.
Docker Hub - A registry of Docker images. You can think of the registry as a directory of all available Docker images. If required, one can host their own Docker registries and can use them for pulling images.
-----------------------------------------------------------------------------------------
# Docker  source - https://prakhar.me/docker-curriculum/
docker -version 
python --version
pip --version
java -version (optional) 
docker pull busybox     #some sample image.The pull command fetches the busybox image from the Docker registry and saves it to our system. You can use the docker images command to see a list of all images on your system
docker images           #list of images on system from docker registry
docker run busybox      #Docker client finds the image (busybox in this case), loads up the container and then runs a command in that container. When we run docker run busybox, we didn't provide a command, so the container booted up, ran an empty command and then exited
docker run busybox echo "hello from busybox"      #If you've noticed, all of that happened pretty quickly. Imagine booting up a virtual machine, running a command and then killing it
docker ps -a            # This will list all contaniners.
docker run -it busybox sh    # here Running the run command with the -it flags attaches us to an interactive tty in the container. Now we can run as many commands in the container as we want
                             e.g. we can run as below 
                              / # ls 
                              / # cd /etc/
  
docker rm $(docker ps -a -q -f status=exited)    # to remove multiple containers 

-----------------------------------------------------------------------------------
# deploying web applications with Docker!

docker run prakhar1989/static-site  # since image doesnot exits locally, it will pull frm registry
# -p switch - the client is not exposing any ports so we need to re-run the docker run command to publish port
# -d switch - we should also find a way so that our terminal is not attached to the running container. This way, you can happily close your terminal and keep the container running. This is called detached mode.

docker run -d -P --name static-site prakhar1989/static-sitee61d12292d69556eabe2a44c16cbd54486b2527e2ce4f95438e504afb7b02810

docker port static-site
docker run -p 8888:80 prakhar1989/static-site    #port 8888 - so this is a custom port to which the client will forward connections to the container.
-----------------------------------------------------------------------------------
# Create our own docker image -
# Docker images are the basis of containers. For simplicity, you can think of an image akin to a git repository - images can be committed with changes and have multiple versions. If you don't provide a specific version number, the client defaults to latest

SO there are three types of images as follows - 
Base images are images that have no parent image, usually images with an OS like ubuntu, busybox or debian.
Child images are images that build on base images and add additional functionality.
User images, which can be both base and child images. These images that are officially maintained and supported by the folks at Docker

------------------------------------------------------------------------------------
# what is onbuild version ? - These images include multiple ONBUILD triggers, which should be all you need to bootstrap most applications. The build will COPY a requirements.txt file, RUN pip install on said file, and then copy the current directory into /usr/src/app.In other words, the onbuild version of the image includes helpers that automate the boring parts of getting an app running. Rather than doing these tasks manually (or scripting these tasks), these images do that work for you

# A Dockerfile is a simple text-file that contains a list of commands that the Docker client calls while creating an image.It's a simple way to automate the image creation process.
                # our base image
                FROM python:3-onbuild
                # specify the port number the container should expose
                EXPOSE 5000
                # run the application
                CMD ["python", "./app.py"]

# The docker build command does the heavy-lifting of creating a Docker image from a Dockerfile.
docker build -t prakhar1989/catnip .
docker run -p 8888:5000 prakhar1989/catnip
This docker image can be pushed to AWS EBS . EBS is PaaS platform by AWS. 
------------------------------------------------------------------------------------
# Multi-container Environments - it involves some kind of persistant storage like Redis and Memcached .it provides isolation. To keep containers for each of the services separate
it is wise to keep containers for each of the services separate sort of a microservices architectures.
# Source - https://prakhar.me/docker-curriculum/ - In this example of food service, it consists of a Flask backend server and elasticsearch service . So 2 things
so a natural way to split this app would be to have two containers - one running the Flask process and another running the Elasticsearch (ES) process.

So Flask backend server container needs following - 
1. Dockerfile 
      - ubuntu base image 
      - python 
      - nodejs to run javascript app page, npm package depenencies etc
              # start from base
              FROM ubuntu:14.04
              MAINTAINER first name last name <test@gmail.com>

              # install system-wide deps for python and node
              RUN apt-get -yqq update
              RUN apt-get -yqq install python-pip python-dev
              RUN apt-get -yqq install nodejs npm
              RUN ln -s /usr/bin/nodejs /usr/bin/node

              # copy our application code
              ADD flask-app /opt/flask-app
              WORKDIR /opt/flask-app

              # fetch app specific deps
              RUN npm install
              RUN npm run build
              RUN pip install -r requirements.txt

              # expose port
              EXPOSE 5000

              # start app
              CMD [ "python", "./app.py" ]
   
      docker build -t prakhar1989/foodtrucks-web .
And Elastic search ES container needs nothing  - docker run -dp 9200:9200 elasticsearch 
-- Now we can connect these two container using Bridge network but it is alwaysa safe to create our own network using (network create) command
docker network create foodtrucks
docker network ls

# Now launch our containers inside this network using the --net flag
docker run -dp 9200:9200 --net foodtrucks --name es elasticsearch

#Now clone actual repo and run whole app using /.setup command as shown below
$ git clone https://github.com/prakhar1989/FoodTrucks
$ cd FoodTrucks
$ ./setup-docker.sh

#This setup-docker.sh has following 4 commands - 
#!/bin/bash
# build the flask container
docker build -t prakhar1989/foodtrucks-web .
# create the network
docker network create foodtrucks
# start the ES container
docker run -d --net foodtrucks -p 9200:9200 -p 9300:9300 --name es elasticsearch
# start the flask app container
docker run -d --net foodtrucks -p 5000:5000 --name foodtrucks-web prakhar1989/foodtrucks-web
------------------------------------------------------------------------------------------------------------------
## Docker-compose 
1. Docker Machine - Create Docker hosts on your computer, on cloud providers, and inside your own data center
2. Docker Compose - A tool for defining and running multi-container Docker applications.
3. Docker Swarm - A native clustering solution for Docker

So docker compose is a tool that is used for defining and running multi-container Docker apps in an easy way. It provides a 
configuration file called docker-compose.yml that can be used to bring up an application and the suite of services it depends on 
with just one command.

#Install docker compose 
pip install docker-compose
docker-compose version

#sample docker-compose.yml file is below
        version: "2"
        services:     
          es:
            image: elasticsearch
          web:
            image: prakhar1989/foodtrucks-web
            command: python app.py
            ports:
              - "5000:5000"
            volumes:
              - .:/code
# At the parent level, we define the names of our services - es and web. For each service, that Docker needs to run, we can add 
# additional parameters out of which image is required. For es, we just refer to the elasticsearch image available on the Docker Hub. 
# For our Flask app, we refer to the image that we built at the beginning of this section. Via other parameters such as command and 
# ports we provide more information about the container. The volumes parameter specifies a mount point in our web container where 
# the code will reside.

docker-compose up

# so basically docker-compose.yml creates network for both the containers (es and web) so earlier , we were creating it manually using create network command.
# Also docker-compose doesnot add host to the /etc/host file, instead it does service discovery using a DNS server. 
-------------------------------------------------------------------

# Deploying docker on AWS cloud (ECS)- 
# AWS ECS is a scalable and super flexible container management service that supports Docker containers. It allows you to operate a 
# Docker cluster on top of EC2 instances via an easy-to-use API. Where Beanstalk came with reasonable defaults, ECS allows you to 
# completely tune your environment as per your needs.

#Deploy docker-compose.yml using ECS CLI commands
ecs-cli --version
ecs-cli configure --region us-east-1 --cluster foodtrucks

# The next step enables the CLI to create a CloudFormation template.
ecs-cli up --keypair ecs --capability-iam --size 2 --instance-type t2.micro
# above, ecs is keypair , size is number of instance we want in the our foodtruck cluster.
# for AWS ECS deloyment , we need to use slightly different docker-compose.yml file to remove few things as below
            es:
              image: elasticsearch
              cpu_shares: 100                   # newly added 
              mem_limit: 262144000              # newly added 
            web:
              image: prakhar1989/foodtrucks-web
              cpu_shares: 100                   # newly added 
              mem_limit: 262144000              # newly added 
              ports:
                - "80:5000"
              links:                             # newly added 
                - es                             # newly added
                
# mem_limit and cpu_shares values for each container
# we removed verson and service from main docker-compose file. ecs-cli does not support the build command
ecs-cli compose --file docker-compose.yml up
ecs-cli ps
# now AWS will wrap this docker-compose under 1 task and called it ECS task. That task will have 2 containers es and web. 

--GIT REPO COde - https://github.com/prakhar1989/docker-curriculum




















